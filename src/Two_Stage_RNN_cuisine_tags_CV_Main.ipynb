{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from embedding import load_emb_vectors, build_emb_weight\n",
    "from loadData import create_dataset_obj, collate_func\n",
    "from model import create_emb_layer, two_stage_RNN, test_model\n",
    "from preprocess import tokenize_dataset, all_tokens_list, build_vocab, token2index_dataset \n",
    "from importlib import reload\n",
    "# reload(loadData)\n",
    "# from loadData import create_dataset_obj, collate_func\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encode the pretrained embedding to text file\n",
    "# model = KeyedVectors.load_word2vec_format('/home/hb1500/Plated/vocab.bin', binary=True)\n",
    "# model.save_word2vec_format('pretrained_embd.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = '../../data/glove.6B.50d.txt'\n",
    "# words_emb_dict = load_emb_vectors(fname)\n",
    "words_emb_dict = {'a': np.zeros(50)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cleaned Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['step_one','step_two', 'step_three', 'step_four', 'step_five', 'step_six']\n",
    "steps_aug = ['step_one_sp', 'step_two_sp', 'step_three_sp',\n",
    "             'step_four_sp', 'step_five_sp', 'step_six_sp']\n",
    "tags = ['tag_cuisine_indian', 'tag_cuisine_nordic', 'tag_cuisine_european',\n",
    "        'tag_cuisine_asian', 'tag_cuisine_mexican',\n",
    "        'tag_cuisine_latin-american', 'tag_cuisine_french',\n",
    "        'tag_cuisine_italian', 'tag_cuisine_african',\n",
    "        'tag_cuisine_mediterranean', 'tag_cuisine_american',\n",
    "        'tag_cuisine_middle-eastern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_aug = pd.read_csv('../data/recipe_data_with_aug.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_aug_tags = data_with_aug[steps+steps_aug+tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['step_one', 'step_two', 'step_three', 'step_four', 'step_five',\n",
      "       'step_six', 'step_one_sp', 'step_two_sp', 'step_three_sp',\n",
      "       'step_four_sp', 'step_five_sp', 'step_six_sp', 'tag_cuisine_indian',\n",
      "       'tag_cuisine_nordic', 'tag_cuisine_european', 'tag_cuisine_asian',\n",
      "       'tag_cuisine_mexican', 'tag_cuisine_latin-american',\n",
      "       'tag_cuisine_french', 'tag_cuisine_italian', 'tag_cuisine_african',\n",
      "       'tag_cuisine_mediterranean', 'tag_cuisine_american',\n",
      "       'tag_cuisine_middle-eastern'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_with_aug_tags.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing original instruction data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangtingyan/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_one has been tokenized.\n",
      "step_two has been tokenized.\n",
      "step_three has been tokenized.\n",
      "step_four has been tokenized.\n",
      "step_five has been tokenized.\n",
      "step_six has been tokenized.\n",
      "Processing augmented instruction data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangtingyan/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_one_sp has been tokenized.\n",
      "step_two_sp has been tokenized.\n",
      "step_three_sp has been tokenized.\n",
      "step_four_sp has been tokenized.\n",
      "step_five_sp has been tokenized.\n",
      "step_six_sp has been tokenized.\n"
     ]
    }
   ],
   "source": [
    "print('Processing original instruction data')\n",
    "# tokenize each steps on original datasets\n",
    "steps_token = []\n",
    "for step in steps:\n",
    "    steps_token.append(step+'_token')\n",
    "    data_with_aug_tags[step+'_token'] = tokenize_dataset(data_with_aug_tags[step])\n",
    "    print(step, 'has been tokenized.')\n",
    "\n",
    "# tokenize each steps on augmented datasets\n",
    "print('Processing augmented instruction data')\n",
    "steps_aug_token = []\n",
    "for step in steps_aug:\n",
    "    steps_aug_token.append(step+'_token')\n",
    "    data_with_aug_tags[step+'_token'] = tokenize_dataset(data_with_aug_tags[step])\n",
    "    print(step, 'has been tokenized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_aug_tags = data_with_aug_tags[steps_token+steps_aug_token+tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step_one_token', 'step_two_token', 'step_three_token',\n",
       "       'step_four_token', 'step_five_token', 'step_six_token',\n",
       "       'step_one_sp_token', 'step_two_sp_token', 'step_three_sp_token',\n",
       "       'step_four_sp_token', 'step_five_sp_token', 'step_six_sp_token',\n",
       "       'tag_cuisine_indian', 'tag_cuisine_nordic', 'tag_cuisine_european',\n",
       "       'tag_cuisine_asian', 'tag_cuisine_mexican',\n",
       "       'tag_cuisine_latin-american', 'tag_cuisine_french',\n",
       "       'tag_cuisine_italian', 'tag_cuisine_african',\n",
       "       'tag_cuisine_mediterranean', 'tag_cuisine_american',\n",
       "       'tag_cuisine_middle-eastern'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_aug_tags.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data, test_data = train_test_split(data_with_aug_tags, test_size=0.1, random_state=RANDOM_STATE)\n",
    "test_data = test_data[steps_token+tags]\n",
    "#train_data, val_data, train_tags, val_tags = train_test_split(X_train, y_train, test_size=0.1, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug2ori_colname = dict(zip(steps_aug_token+tags, steps_token+tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation for train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_predicted = ['tag_cuisine_american']\n",
    "\n",
    "test_targets = []\n",
    "for row in test_data[tags_predicted].iterrows():\n",
    "    test_targets.append(list(row[1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_types = {\n",
    "    'rnn': nn.RNN,\n",
    "    'lstm': nn.LSTM,\n",
    "    'gru': nn.GRU\n",
    "}\n",
    "\n",
    "params = dict(\n",
    "    rnn1_type = 'gru',\n",
    "    rnn2_type = 'gru',\n",
    "    bi = True,\n",
    "    tags_predicted = tags_predicted,\n",
    "    \n",
    "    hidden_dim1 = 30,\n",
    "    hidden_dim2 = 30,\n",
    "    num_classes = 1,\n",
    "    \n",
    "    multi_task_train = None, #{'mean_loss', 'random_selection'}\n",
    "    num_epochs = 10,\n",
    "    batch_size = 50,\n",
    "    learning_rate = 0.01,\n",
    "    step_max_descent = 3,\n",
    "    \n",
    "    add_data_aug = True,\n",
    "    cuda_on = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== This is the Kfold 1 =====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangtingyan/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train parameters 23071\n",
      "1/10, Step:1/73, TrainLoss:0.698178, ValAUC:[0.49947161237483817] ValAcc:[0.754424778761062]\n",
      "1/10, Step:11/73, TrainLoss:0.589456, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "1/10, Step:21/73, TrainLoss:0.551705, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "1/10, Step:31/73, TrainLoss:0.738154, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "1/10, Step:41/73, TrainLoss:0.668641, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "1/10, Step:51/73, TrainLoss:0.653770, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "1/10, Step:61/73, TrainLoss:0.580003, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "1/10, Step:71/73, TrainLoss:0.666417, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "Epoch: [1/10], trainAUC: [0.5], trainAcc: [0.7191135734072022]\n",
      "Epoch: [1/10], ValAUC: [0.5], ValAcc: [0.754424778761062]\n",
      "2/10, Step:1/73, TrainLoss:0.575575, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "2/10, Step:11/73, TrainLoss:0.595080, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "2/10, Step:21/73, TrainLoss:0.557019, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "2/10, Step:31/73, TrainLoss:0.638333, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "2/10, Step:41/73, TrainLoss:0.694038, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "2/10, Step:51/73, TrainLoss:0.584204, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "2/10, Step:61/73, TrainLoss:0.627063, ValAUC:[0.5] ValAcc:[0.754424778761062]\n",
      "2/10, Step:71/73, TrainLoss:0.459336, ValAUC:[0.5] ValAcc:[0.754424778761062]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-571d08d5e884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                            collate_func)\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mval_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mval_auc_kf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-93f5e64f2ee5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(params, emb_weight, train_loader, val_loader, test_loader)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 print('{}/{}, Step:{}/{}, TrainLoss:{:.6f}, ValAUC:{} ValAcc:{}'.format(\n\u001b[1;32m     61\u001b[0m                     epoch+1, num_epochs, i+1, len(train_loader), loss, val_auc, val_acc))\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mval_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: [{}/{}], trainAUC: {}, trainAcc: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/CapstoneProject/Plated_Recipe_Tags_Predict/src/model.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mlengths_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0msteps_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlogits_all_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/CapstoneProject/Plated_Recipe_Tags_Predict/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, steps, lengths)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_each_step\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, self.hidden_stage1[str(i)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "k = 1 \n",
    "val_auc_kf = []\n",
    "for train_index, val_index in kf.split(train_val_data):\n",
    "    print('===================== This is the Kfold {} ====================='.format(k))\n",
    "    k += 1\n",
    "    val_data = train_val_data[steps_token+tags].iloc[val_index]\n",
    "    train_data = train_val_data.iloc[train_index]\n",
    "    \n",
    "    if params['add_data_aug']:\n",
    "        ##### add augmentation to training set by index #####\n",
    "        train_org = train_data[steps_token+tags]\n",
    "        train_aug = train_data[steps_aug_token+tags]\n",
    "        train_aug.rename(index=str, columns=aug2ori_colname, inplace=True)\n",
    "        train_data = pd.concat([train_org, train_aug], axis=0, ignore_index=False)\n",
    "        ##### add augmentation to training set by index #####\n",
    "    else:\n",
    "        train_data = train_data[steps_token+tags]\n",
    "    \n",
    "    train_targets = []\n",
    "    for row in train_data[tags_predicted].iterrows():\n",
    "        train_targets.append(list(row[1].values))\n",
    "    val_targets = []\n",
    "    for row in val_data[tags_predicted].iterrows():\n",
    "        val_targets.append(list(row[1].values))\n",
    "    \n",
    "    train_X = train_data[steps_token]\n",
    "    val_X = val_data[steps_token]\n",
    "    test_X = test_data[steps_token]\n",
    "    all_train_tokens = all_tokens_list(train_X)\n",
    "    max_vocab_size = len(list(set(all_train_tokens)))\n",
    "    token2id, id2token = build_vocab(all_train_tokens, max_vocab_size)\n",
    "    emb_weight = build_emb_weight(words_emb_dict, id2token)\n",
    "    train_data_indices = token2index_dataset(train_X, token2id)\n",
    "    val_data_indices = token2index_dataset(val_X, token2id)\n",
    "    test_data_indices = token2index_dataset(test_X, token2id)\n",
    "\n",
    "    # batchify datasets: \n",
    "    batch_size = params['batch_size']\n",
    "    max_sent_len = np.array([94, 86, 87, 90, 98, 91])\n",
    "    train_loader, val_loader, test_loader = create_dataset_obj(train_data_indices, val_data_indices,\n",
    "                                                           test_data_indices, train_targets,\n",
    "                                                           val_targets, test_targets,\n",
    "                                                           batch_size, max_sent_len, \n",
    "                                                           collate_func)\n",
    "    \n",
    "    val_auc, val_acc = train_model(params, emb_weight, train_loader, val_loader, test_loader)\n",
    "    val_auc_kf.append(val_auc)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "def train_model(params, emb_weight, train_loader, val_loader, test_loader):\n",
    "    tags_predicted = params['tags_predicted']\n",
    "    num_tasks = len(tags_predicted)\n",
    "    rnn1_type = params['rnn1_type'] \n",
    "    rnn_1 = rnn_types[rnn1_type]\n",
    "    rnn2_type = params['rnn2_type']\n",
    "    rnn_2 = rnn_types[rnn2_type]\n",
    "    bi = params['bi']\n",
    "    hidden_dim1 = params['hidden_dim1']\n",
    "    hidden_dim2 = params['hidden_dim2']\n",
    "    \n",
    "    multi_task_train = params['multi_task_train'] \n",
    "    num_classes = params['num_classes']\n",
    "    batch_size = params['batch_size']\n",
    "    cuda_on = params['cuda_on']\n",
    "\n",
    "    weights_matrix = torch.from_numpy(emb_weight)\n",
    "    model = two_stage_RNN(rnn_1, hidden_dim1, bi, rnn_2, hidden_dim2, batch_size, \n",
    "                          cuda_on, weights_matrix, num_tasks, num_classes)\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    print('The number of train parameters', sum([np.prod(p.size()) for p in model_parameters]))\n",
    "    model = model.to(device)\n",
    "\n",
    "    #parameter for training\n",
    "    learning_rate = params['learning_rate']\n",
    "    num_epochs = params['num_epochs'] # number epoch to train\n",
    "\n",
    "    # Criterion and Optimizer\n",
    "    #pos_weight=torch.Tensor([40,]).cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss() #torch.nn.BCELoss(); torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_loss_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (steps_batch, lengths_batch, labels_batch) in enumerate(train_loader):\n",
    "            for step_id in range(6):\n",
    "                lengths_batch[step_id] = lengths_batch[step_id].to(device)\n",
    "                steps_batch[step_id] = steps_batch[step_id].to(device)\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(steps_batch, lengths_batch)\n",
    "            if num_tasks == 1:\n",
    "                task_id = 0\n",
    "            else:\n",
    "                print('Task number is greater than 1')\n",
    "            loss = criterion(logits[task_id], labels_batch[task_id].view(-1,1).float().to(device))\n",
    "            train_loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 100 iterations\n",
    "            if i % 10 == 0:\n",
    "                # validate\n",
    "#                 print('---------------------')\n",
    "#                 for p in model.parameters():\n",
    "#                     if p.requires_grad:\n",
    "#                         print(p.name, p.size(), p.requires_grad, torch.mean(torch.abs(p.data)), torch.mean(torch.abs(p.grad)))\n",
    "#                         break\n",
    "                val_auc, val_acc = test_model(val_loader, model)\n",
    "                print('{}/{}, Step:{}/{}, TrainLoss:{:.6f}, ValAUC:{} ValAcc:{}'.format(\n",
    "                    epoch+1, num_epochs, i+1, len(train_loader), loss, val_auc, val_acc))\n",
    "        val_auc, val_acc = test_model(val_loader, model)\n",
    "        train_auc, train_acc = test_model(train_loader, model)\n",
    "        print('Epoch: [{}/{}], trainAUC: {}, trainAcc: {}'.format(epoch+1, num_epochs, train_auc, train_acc))\n",
    "        print('Epoch: [{}/{}], ValAUC: {}, ValAcc: {}'.format(epoch+1, num_epochs, val_auc, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_cuisine_indian            0.023525\n",
       "tag_cuisine_nordic            0.000399\n",
       "tag_cuisine_european          0.012360\n",
       "tag_cuisine_asian             0.182217\n",
       "tag_cuisine_mexican           0.013557\n",
       "tag_cuisine_latin-american    0.094896\n",
       "tag_cuisine_french            0.077352\n",
       "tag_cuisine_italian           0.233254\n",
       "tag_cuisine_african           0.003987\n",
       "tag_cuisine_mediterranean     0.076555\n",
       "tag_cuisine_american          0.273525\n",
       "tag_cuisine_middle-eastern    0.046252\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cuisine_tags.iloc[:,1:].sum()/data_cuisine_tags.iloc[:,1:].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose tag: tag_cuisine_american, which 27.3525% are 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct data strcuture for datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag_cuisine_indian            0.023525  85% auc\n",
    "tag_cuisine_nordic            0.000399\n",
    "tag_cuisine_european          0.012360\n",
    "tag_cuisine_asian             0.182217  98% auc\n",
    "tag_cuisine_mexican           0.013557\n",
    "tag_cuisine_latin-american    0.094896  90% auc\n",
    "tag_cuisine_french            0.077352  72% auc\n",
    "tag_cuisine_italian           0.233254  80% auc\n",
    "tag_cuisine_african           0.003987\n",
    "tag_cuisine_mediterranean     0.076555  88% auc\n",
    "tag_cuisine_american          0.273525  80% auc\n",
    "tag_cuisine_middle-eastern    0.046252  87% auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "logits_all = []\n",
    "labels_all = []\n",
    "model.eval()\n",
    "for steps_batch, lengths_batch, labels_batch in test_loader:\n",
    "    for step_id in range(6):\n",
    "        lengths_batch[step_id] = lengths_batch[step_id].to(device)\n",
    "        steps_batch[step_id] = steps_batch[step_id].to(devi) \n",
    "    logits = model(steps_batch, lengths_batch)\n",
    "    logits_all.extend(list(logits.cpu().detach().numpy()))\n",
    "    labels_all.extend(list(labels_batch.numpy()))\n",
    "logits_all = np.array(logits_all)\n",
    "labels_all = np.array(labels_all)\n",
    "auc = roc_auc_score(labels_all, logits_all)\n",
    "predicts = (logits_all > 0.5).astype(int)\n",
    "acc = np.mean(predicts==labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82168113146898103"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b342ac7c588>]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b342a7a5160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels_all, logits_all, pos_label=1)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
